{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import mplfinance as mpf\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.cluster.hierarchy import ward, fcluster\n",
    "from statsmodels.nonparametric.kernel_regression import KernelReg\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from matplotlib.pyplot import axes\n",
    "from pyparsing import alphas\n",
    "from cProfile import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette_coefficient(data):\n",
    "    data_reshape = np.reshape(data, (-1, 1))\n",
    "\n",
    "    scores = []\n",
    "    coefficient = []\n",
    "    \n",
    "    for k in range(2,4):\n",
    "        estimator = KMeans (n_clusters = k)\n",
    "        estimator.fit(data_reshape)\n",
    "        try:\n",
    "            scores.append(silhouette_score(data_reshape,estimator.labels_,metric='euclidean'))\n",
    "        except ValueError:\n",
    "            scores.append(0)\n",
    "        coefficient.append(k)\n",
    "    \n",
    "    index_of_max = scores.index(max(scores))\n",
    "    return coefficient[index_of_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_create(df, **kwargs):\n",
    "    for i in kwargs.items():\n",
    "        if i[0] == 'drop':\n",
    "            df_total = df.drop(i[1], axis=1)\n",
    "        elif i[0] == 'timestamp':\n",
    "            df_total['timestamp'] = pd.to_datetime(df_total['timestamp'], unit=i[1])\n",
    "    return df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouping_by_time(df, frequency = 'min', round = 5):\n",
    "    grouped_price = df.groupby([pd.Grouper(\n",
    "    key='timestamp', freq=frequency)]).agg(\n",
    "        Open = ('price', 'first'),\n",
    "        High = ('price', 'max'),\n",
    "        Low = ('price', 'min'),\n",
    "        Close = ('price', 'last'),\n",
    "        Volume = ('size', 'sum'), ).round(round)\n",
    "\n",
    "    # clearing nan-values\n",
    "    grouped_price = grouped_price.fillna(method=\"ffill\")\n",
    "    grouped_price = grouped_price.fillna(method=\"bfill\")\n",
    "    return grouped_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extremes_search(in_array):\n",
    "    val_max, val_min, indexes_max, indexes_min = [], [], [], []\n",
    "    for i in range(1, len(in_array)-1):\n",
    "        if in_array[i] > in_array[i-1]:\n",
    "            if in_array[i] > in_array[i+1]:\n",
    "                val_max.append(in_array[i])\n",
    "                indexes_max.append(i)\n",
    "\n",
    "    for i in range(0, len(in_array)-1):\n",
    "        if in_array[i] < in_array[i-1]:\n",
    "            if in_array[i] < in_array[i+1]:\n",
    "                val_min.append(in_array[i])\n",
    "                indexes_min.append(i)\n",
    "    return val_max, val_min, indexes_max, indexes_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def touch_count(in_array, threshold):\n",
    "    touches = []\n",
    "    level_prices = []\n",
    "    for i in in_array:\n",
    "        distance_to_level = abs(i - in_array)\n",
    "        touches = np.where(distance_to_level < threshold)\n",
    "\n",
    "    max_index = np.where(in_array == max(in_array))[0][0]\n",
    "\n",
    "    for i in range(max_index, len(in_array)):\n",
    "        distance_to_level = abs(in_array[i] - in_array)\n",
    "        touches = np.where(distance_to_level < threshold)\n",
    "\n",
    "        if len(touches[0]) >= 5:\n",
    "            #index = np.where(p_smooth == in_array[i])[0]\n",
    "            #plt.hlines(val_max[i], t[index], t.max(), color = 'b', alpha = 0.2)\n",
    "            #levels.append([len(touches[0]), in_array[i]])\n",
    "            level_prices.append(in_array[i])\n",
    "    return level_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_create(x, y, quotation, levels, cluster_numbers, threshold, diff_percent):\n",
    "  fig, ax = plt.subplots(figsize=(16, 8))\n",
    "  plt.title(label=quotation)\n",
    "  ax.grid()\n",
    "  ax.plot(x, y)\n",
    "\n",
    "  levels_txt = \"\"\n",
    "  if len(levels) == 0:\n",
    "    levels_txt = \"levels not found\"\n",
    "  else:\n",
    "    for i in levels:\n",
    "      ax.hlines(i, x.min(), x.max(), color = 'r', alpha = 0.5)\n",
    "      levels_txt = levels_txt + \" \" + str(i.round(2))\n",
    "\n",
    "  tx = (\"level = \" + levels_txt + '\\n' + \n",
    "        \"cluster count = \" + str(cluster_numbers) + '\\n' + \n",
    "        \"threshold = \" + str(threshold.round(5)) + '\\n' + \n",
    "        \"diff_percent = \" + str(diff_percent.round(5)) + \"%\"\n",
    "    )\n",
    "\n",
    "  ax.text(x.min(), y.min(), tx, size = 13)\n",
    "\n",
    "  return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resistance_search(quotation, df_path):\n",
    "    savgol_filter_param = 50\n",
    "\n",
    "    df_raw = pd.read_csv(df_path)\n",
    "\n",
    "    # open datasets and create dataframe\n",
    "    df = dataframe_create(df=df_raw,\n",
    "                          drop=['symbol', 'tickDirection', 'trdMatchID', \n",
    "                                'side', 'grossValue', 'homeNotional', \n",
    "                                'foreignNotional'\n",
    "                                ],\n",
    "                          timestamp = 's'\n",
    "                          )\n",
    "\n",
    "    # gpouping data to tameframe\n",
    "    minutly_price = grouping_by_time(df)\n",
    "\n",
    "    new_prices = minutly_price[1000:-1000]\n",
    "\n",
    "    # from dataframe to numpy array\n",
    "    p = np.array(new_prices['High'])\n",
    "    t = np.array(new_prices.index)\n",
    "\n",
    "    # smoothing\n",
    "    p_smooth = savgol_filter(p, savgol_filter_param, 3)\n",
    "\n",
    "    # searching local extremes\n",
    "    val_max, val_min, indexes_max, indexes_min = extremes_search(p_smooth)\n",
    "\n",
    "    # set the threshold and percent difference\n",
    "    th = 0.1\n",
    "    diff_percent = (np.max(p) - np.min(p))/np.max(p)\n",
    "\n",
    "    threshold = diff_percent * th * np.min(p_smooth)\n",
    "\n",
    "    # level touch count for max\n",
    "    level_prices = touch_count(val_max, threshold)\n",
    "\n",
    "    resistance_levels = []\n",
    "    cluster_numbers = 0\n",
    "\n",
    "    if len(level_prices) > 1:\n",
    "        if len(level_prices) > 10:\n",
    "            # clusters count\n",
    "            cluster_numbers = silhouette_coefficient(level_prices)\n",
    "\n",
    "            # one-cluster detection (if clusters > 2 -> cluster only one)    \n",
    "            if cluster_numbers <= 2:\n",
    "                level_prices_reshape = np.reshape(level_prices, (-1, 1))\n",
    "\n",
    "                kmeans = KMeans(n_clusters = cluster_numbers)\n",
    "                kmeans.fit(level_prices_reshape)\n",
    "\n",
    "                labels = kmeans.labels_\n",
    "                for i in range(cluster_numbers):\n",
    "                    indexes = np.where(labels == i)[0]\n",
    "                    max_index = np.min(indexes)\n",
    "\n",
    "                    resistance_levels.append(level_prices[max_index])\n",
    "            else:\n",
    "                resistance_levels.append(max(level_prices))\n",
    "        else:\n",
    "            resistance_levels.append(max(level_prices))\n",
    "\n",
    "    # plot create\n",
    "    return plot_create(t, p, quotation, resistance_levels, cluster_numbers, threshold, diff_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real data run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10000NFTUSDT.csv', '1000BTTUSDT.csv', '1000XECUSDT.csv', '1INCHUSDT.csv', 'AAVEUSDT.csv', 'ACHUSDT.csv', 'ADAUSD.csv', 'ADAUSDT.csv', 'AGLDUSDT.csv', 'AKROUSDT.csv', 'ALGOUSDT.csv', 'ALICEUSDT.csv', 'ALPHAUSDT.csv', 'ANKRUSDT.csv', 'ANTUSDT.csv', 'APEUSDT.csv', 'API3USDT.csv', 'ARPAUSDT.csv', 'ARUSDT.csv', 'ASTRUSDT.csv', 'AUDIOUSDT.csv', 'AVAXUSDT.csv', 'AXSUSDT.csv', 'BAKEUSDT.csv', 'BALUSDT.csv', 'BANDUSDT.csv', 'BATUSDT.csv', 'BCHUSDT.csv', 'BELUSDT.csv', 'BICOUSDT.csv', 'BITUSD.csv', 'BITUSDT.csv', 'BLZUSDT.csv', 'BNBUSDT.csv', 'BNXUSDT.csv', 'BOBAUSDT.csv', 'BSVUSDT.csv', 'BSWUSDT.csv', 'BTCUSD.csv', 'BTCUSDT.csv', 'C98USDT.csv', 'CEEKUSDT.csv', 'CELOUSDT.csv', 'CELRUSDT.csv', 'CHRUSDT.csv', 'CHZUSDT.csv', 'CKBUSDT.csv', 'COMPUSDT.csv', 'COTIUSDT.csv', 'CREAMUSDT.csv', 'CROUSDT.csv', 'CRVUSDT.csv', 'CTCUSDT.csv', 'CTKUSDT.csv', 'CTSIUSDT.csv', 'CVCUSDT.csv', 'CVXUSDT.csv', 'DARUSDT.csv', 'DASHUSDT.csv', 'DENTUSDT.csv', 'DGBUSDT.csv', 'DODOUSDT.csv', 'DOGEUSDT.csv', 'DOTUSD.csv', 'DOTUSDT.csv', 'DUSKUSDT.csv', 'DYDXUSDT.csv', 'EGLDUSDT.csv', 'ENJUSDT.csv', 'ENSUSDT.csv', 'EOSUSD.csv', 'EOSUSDT.csv', 'ETCUSDT.csv', 'ETHUSD.csv', 'ETHUSDT.csv', 'FILUSDT.csv', 'FITFIUSDT.csv', 'FLMUSDT.csv', 'FLOWUSDT.csv', 'FTMUSDT.csv', 'FTTUSDT.csv', 'FXSUSDT.csv', 'GALAUSDT.csv', 'GALUSDT.csv', 'GLMRUSDT.csv', 'GMTUSDT.csv', 'GRTUSDT.csv', 'GTCUSDT.csv', 'HBARUSDT.csv', 'HNTUSDT.csv', 'HOTUSDT.csv', 'ICPUSDT.csv', 'ICXUSDT.csv', 'ILVUSDT.csv', 'IMXUSDT.csv', 'IOSTUSDT.csv', 'IOTAUSDT.csv', 'IOTXUSDT.csv', 'JASMYUSDT.csv', 'JSTUSDT.csv', 'KAVAUSDT.csv', 'KDAUSDT.csv', 'KLAYUSDT.csv', 'KNCUSDT.csv', 'KSMUSDT.csv', 'LDOUSDT.csv', 'LINAUSDT.csv', 'LINKUSDT.csv', 'LITUSDT.csv', 'LOOKSUSDT.csv', 'LPTUSDT.csv', 'LRCUSDT.csv', 'LTCUSD.csv', 'LTCUSDT.csv', 'LUNA2USDT.csv', 'MANAUSD.csv', 'MANAUSDT.csv', 'MASKUSDT.csv', 'MATICUSDT.csv', 'MINAUSDT.csv', 'MKRUSDT.csv', 'MTLUSDT.csv', 'NEARUSDT.csv', 'NEOUSDT.csv', 'OCEANUSDT.csv', 'OGNUSDT.csv', 'OMGUSDT.csv', 'ONEUSDT.csv', 'ONTUSDT.csv', 'OPUSDT.csv', 'PAXGUSDT.csv', 'PEOPLEUSDT.csv', 'QTUMUSDT.csv', 'RAYUSDT.csv', 'REEFUSDT.csv', 'RENUSDT.csv', 'REQUSDT.csv', 'RNDRUSDT.csv', 'ROSEUSDT.csv', 'RSRUSDT.csv', 'RSS3USDT.csv', 'RUNEUSDT.csv', 'RVNUSDT.csv', 'SANDUSDT.csv', 'SCRTUSDT.csv', 'SCUSDT.csv', 'SFPUSDT.csv', 'SHIB1000USDT.csv', 'SKLUSDT.csv', 'SLPUSDT.csv', 'SNXUSDT.csv', 'SOLUSD.csv', 'SOLUSDT.csv', 'SRMUSDT.csv', 'STMXUSDT.csv', 'STORJUSDT.csv', 'STXUSDT.csv', 'SUNUSDT.csv', 'SUSHIUSDT.csv', 'SXPUSDT.csv', 'THETAUSDT.csv', 'TLMUSDT.csv', 'TOMOUSDT.csv', 'TRBUSDT.csv', 'TRXUSDT.csv', 'UNFIUSDT.csv', 'UNIUSDT.csv', 'USDCUSDT.csv', 'VETUSDT.csv', 'WAVESUSDT.csv', 'WOOUSDT.csv', 'XEMUSDT.csv', 'XLMUSDT.csv', 'XMRUSDT.csv', 'XRPUSD.csv', 'XRPUSDT.csv', 'XTZUSDT.csv', 'YFIUSDT.csv', 'YGGUSDT.csv', 'ZECUSDT.csv', 'ZENUSDT.csv', 'ZILUSDT.csv', 'ZRXUSDT.csv']\n",
      "['10000NFTUSDT', 'csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dirname = 'market_history'\n",
    "files = os.listdir(dirname)\n",
    "\n",
    "print(files)\n",
    "print(files[0].split('.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post to telegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def send_telegram(text: str):\n",
    "    token = \"5582704464:AAFNVAt5QFmeqp5bXEXdaYrT5pw8UYP5bhs\"\n",
    "    url = \"https://api.telegram.org/bot\"\n",
    "    channel_id = \"@level_signals\"\n",
    "    url += token\n",
    "    method = url + \"/sendMessage\"\n",
    "\n",
    "    r = requests.post(method, data={\n",
    "         \"chat_id\": channel_id,\n",
    "         \"text\": text\n",
    "          })\n",
    "\n",
    "    if r.status_code != 200:\n",
    "        raise Exception(\"post_text error\")\n",
    "\n",
    "send_telegram(\"hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in files:\n",
    "    quotation = i.split('.')[0]\n",
    "    df_path = 'market_history/' + quotation + '.csv'\n",
    "\n",
    "    pic = resistance_search(quotation, df_path)\n",
    "    path = 'images/' + quotation + '.png'\n",
    "    pic.savefig(path)\n",
    "\n",
    "    url = \"https://api.telegram.org/bot5582704464:AAFNVAt5QFmeqp5bXEXdaYrT5pw8UYP5bhs/sendPhoto\"\n",
    "    files = {'photo': open(path, 'rb')}\n",
    "    data = {'chat_id' : \"@level_signals\"}\n",
    "    r= requests.post(url, files=files, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = 'data:image/png;base64,' + urllib.parse.quote(string)\n",
    "html = '<img src = \"%s\"/>' % uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "print(type(string))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23a869f485f770016e34d0b646821068146fc1223f42d88213feb34af8b00711"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
