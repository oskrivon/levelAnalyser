{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import mplfinance as mpf\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.cluster.hierarchy import ward, fcluster\n",
    "from statsmodels.nonparametric.kernel_regression import KernelReg\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from matplotlib.pyplot import axes\n",
    "from pyparsing import alphas\n",
    "from cProfile import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette_coefficient(data):\n",
    "    data_reshape = np.reshape(data, (-1, 1))\n",
    "\n",
    "    scores = []\n",
    "    coefficient = []\n",
    "    \n",
    "    for k in range(2,4):\n",
    "        estimator = KMeans (n_clusters = k)\n",
    "        estimator.fit(data_reshape)\n",
    "        try:\n",
    "            scores.append(silhouette_score(data_reshape,estimator.labels_,metric='euclidean'))\n",
    "        except ValueError:\n",
    "            scores.append(0)\n",
    "        coefficient.append(k)\n",
    "    \n",
    "    index_of_max = scores.index(max(scores))\n",
    "    return coefficient[index_of_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_create(df, **kwargs):\n",
    "    for i in kwargs.items():\n",
    "        if i[0] == 'drop':\n",
    "            df_total = df.drop(i[1], axis=1)\n",
    "        elif i[0] == 'timestamp':\n",
    "            df_total['timestamp'] = pd.to_datetime(df_total['timestamp'], unit=i[1])\n",
    "    return df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouping_by_time(df, frequency = 'min', round = 5):\n",
    "    grouped_price = df.groupby([pd.Grouper(\n",
    "    key='timestamp', freq=frequency)]).agg(\n",
    "        Open = ('price', 'first'),\n",
    "        High = ('price', 'max'),\n",
    "        Low = ('price', 'min'),\n",
    "        Close = ('price', 'last'),\n",
    "        Volume = ('size', 'sum'), ).round(round)\n",
    "\n",
    "    # clearing nan-values\n",
    "    grouped_price = grouped_price.fillna(method=\"ffill\")\n",
    "    grouped_price = grouped_price.fillna(method=\"bfill\")\n",
    "    return grouped_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extremes_search(in_array):\n",
    "    val_max, val_min, indexes_max, indexes_min = [], [], [], []\n",
    "    for i in range(1, len(in_array)-1):\n",
    "        if in_array[i] > in_array[i-1]:\n",
    "            if in_array[i] > in_array[i+1]:\n",
    "                val_max.append(in_array[i])\n",
    "                indexes_max.append(i)\n",
    "\n",
    "    for i in range(0, len(in_array)-1):\n",
    "        if in_array[i] < in_array[i-1]:\n",
    "            if in_array[i] < in_array[i+1]:\n",
    "                val_min.append(in_array[i])\n",
    "                indexes_min.append(i)\n",
    "    return val_max, val_min, indexes_max, indexes_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def touch_count(in_array, threshold):\n",
    "    touches = []\n",
    "    level_prices = []\n",
    "    for i in in_array:\n",
    "        distance_to_level = abs(i - in_array)\n",
    "        touches = np.where(distance_to_level < threshold)\n",
    "\n",
    "    max_index = np.where(in_array == max(in_array))[0][0]\n",
    "\n",
    "    for i in range(max_index, len(in_array)):\n",
    "        distance_to_level = abs(in_array[i] - in_array)\n",
    "        touches = np.where(distance_to_level < threshold)\n",
    "\n",
    "        if len(touches[0]) >= 5:\n",
    "            #index = np.where(p_smooth == in_array[i])[0]\n",
    "            #plt.hlines(val_max[i], t[index], t.max(), color = 'b', alpha = 0.2)\n",
    "            #levels.append([len(touches[0]), in_array[i]])\n",
    "            level_prices.append(in_array[i])\n",
    "    return level_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_create(x, y, quotation, levels, cluster_numbers, threshold, diff_percent):\n",
    "  fig, ax = plt.subplots(figsize=(16, 8))\n",
    "  plt.title(label=quotation)\n",
    "  ax.grid()\n",
    "  ax.plot(x, y)\n",
    "\n",
    "  levels_txt = \"\"\n",
    "  if len(levels) == 0:\n",
    "    levels_txt = \"levels not found\"\n",
    "  else:\n",
    "    for i in levels:\n",
    "      ax.hlines(i, x.min(), x.max(), color = 'r', alpha = 0.5)\n",
    "      levels_txt = levels_txt + \" \" + str(i.round(2))\n",
    "\n",
    "  tx = (\"level = \" + levels_txt + '\\n' + \n",
    "        \"cluster count = \" + str(cluster_numbers) + '\\n' + \n",
    "        \"threshold = \" + str(threshold.round(5)) + '\\n' + \n",
    "        \"diff_percent = \" + str(diff_percent.round(5)) + \"%\"\n",
    "    )\n",
    "\n",
    "  ax.text(x.min(), y.min(), tx, size = 13)\n",
    "\n",
    "  return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resistance_search(quotation, df_path):\n",
    "    savgol_filter_param = 50\n",
    "\n",
    "    df_raw = pd.read_csv(df_path)\n",
    "\n",
    "    # open datasets and create dataframe\n",
    "    df = dataframe_create(df=df_raw,\n",
    "                          drop=['symbol', 'tickDirection', 'trdMatchID', \n",
    "                                'side', 'grossValue', 'homeNotional', \n",
    "                                'foreignNotional'\n",
    "                                ],\n",
    "                          timestamp = 's'\n",
    "                          )\n",
    "\n",
    "    # gpouping data to tameframe\n",
    "    minutly_price = grouping_by_time(df)\n",
    "\n",
    "    new_prices = minutly_price[1000:-1000]\n",
    "\n",
    "    # from dataframe to numpy array\n",
    "    p = np.array(new_prices['High'])\n",
    "    t = np.array(new_prices.index)\n",
    "\n",
    "    # smoothing\n",
    "    p_smooth = savgol_filter(p, savgol_filter_param, 3)\n",
    "\n",
    "    # searching local extremes\n",
    "    val_max, val_min, indexes_max, indexes_min = extremes_search(p_smooth)\n",
    "\n",
    "    # set the threshold and percent difference\n",
    "    th = 0.1\n",
    "    diff_percent = (np.max(p) - np.min(p))/np.max(p)\n",
    "\n",
    "    threshold = diff_percent * th * np.min(p_smooth)\n",
    "\n",
    "    # level touch count for max\n",
    "    level_prices = touch_count(val_max, threshold)\n",
    "\n",
    "    resistance_levels = []\n",
    "    cluster_numbers = 0\n",
    "\n",
    "    if len(level_prices) > 1:\n",
    "        if len(level_prices) > 10:\n",
    "            # clusters count\n",
    "            cluster_numbers = silhouette_coefficient(level_prices)\n",
    "\n",
    "            # one-cluster detection (if clusters > 2 -> cluster only one)    \n",
    "            if cluster_numbers <= 2:\n",
    "                level_prices_reshape = np.reshape(level_prices, (-1, 1))\n",
    "\n",
    "                kmeans = KMeans(n_clusters = cluster_numbers)\n",
    "                kmeans.fit(level_prices_reshape)\n",
    "\n",
    "                labels = kmeans.labels_\n",
    "                for i in range(cluster_numbers):\n",
    "                    indexes = np.where(labels == i)[0]\n",
    "                    max_index = np.min(indexes)\n",
    "\n",
    "                    resistance_levels.append(level_prices[max_index])\n",
    "            else:\n",
    "                resistance_levels.append(max(level_prices))\n",
    "        else:\n",
    "            resistance_levels.append(max(level_prices))\n",
    "\n",
    "    # plot create\n",
    "    return plot_create(t, p, quotation, resistance_levels, cluster_numbers, threshold, diff_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real data run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23a869f485f770016e34d0b646821068146fc1223f42d88213feb34af8b00711"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
